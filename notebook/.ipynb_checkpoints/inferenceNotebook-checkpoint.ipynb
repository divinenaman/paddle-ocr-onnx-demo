{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import * as ort from 'onnxruntime-node';\n",
    "import ndarray from 'ndarray'\n",
    "import ops from 'ndarray-ops'\n",
    "import fs from 'node:fs'\n",
    "import jimp from 'jimp'\n",
    "\n",
    "const { cv, cvTranslateError } = require('opencv-wasm');\n",
    "\n",
    "var text = fs.readFileSync(\"classes.txt\").toString('utf-8');\n",
    "const classes = text.split(\"\\r\\n\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "var path = 'https://gssc.esa.int/navipedia/images/a/a9/Example.jpg'\n",
    "var imageData = null;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "var imageData = await jimp.read(path).then(image => {\n",
    "    return image.resize(640, 640) // resize\n",
    "    //console.log(imageData.bitmap)\n",
    "      //.quality(60) // set JPEG quality\n",
    "      //.greyscale() // set greyscale\n",
    "      //.write('./data/bird-small-bw.jpg'); // save\n",
    "  })\n",
    "  .catch(err => {\n",
    "    console.error(err);\n",
    "  });"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "function imageDataToTensor(data, dims): any {\n",
    "    // 1a. Extract the R, G, and B channels from the data to form a 3D int array\n",
    "    const [R, G, B] = new Array([], [], []);\n",
    "    for (let i = 0; i < data.length; i += 4) {\n",
    "      R.push(data[i]);\n",
    "      G.push(data[i + 1]);\n",
    "      B.push(data[i + 2]);\n",
    "      // 2. skip data[i + 3] thus filtering out the alpha channel\n",
    "    }\n",
    "    ///console.log(R);\n",
    "    //console.log(G);\n",
    "    //console.log(B);\n",
    "    // 1b. concatenate RGB ~= transpose [224, 224, 3] -> [3, 224, 224]\n",
    "    const transposedData = R.concat(G).concat(B);\n",
    "\n",
    "    // 3. convert to float32\n",
    "    let i, l = transposedData.length; // length, we need this for the loop\n",
    "    const float32Data = new Float32Array(3 * 640 * 640); // create the Float32Array for output\n",
    "    for (i = 0; i < l; i++) {\n",
    "      float32Data[i] = transposedData[i] / 255.0; // convert to float\n",
    "    }\n",
    "  \n",
    "    const inputTensor = new ort.Tensor(\"float32\", float32Data, dims);\n",
    "    return inputTensor;\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "var data = imageDataToTensor(imageData.bitmap.data, [1, 3, 640, 640])\n",
    "// create an inference session, using WebGL backend. (default is 'wasm') \n",
    "//const session = await ort.InferenceSession.create('./model/squeezenet1_1.onnx', { executionProviders: ['wasm'] }); \n",
    "const session = await ort.InferenceSession.create('../model/det_onnx/model.onnx', { executionProviders: ['cpu'] });"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "async function runModel(model, preprocessedData): Promise<[Tensor, number]> {\n",
    "    const start = new Date();\n",
    "    try {\n",
    "      const feeds: Record<string, Tensor> = {};\n",
    "      feeds[model.inputNames[0]] = preprocessedData;\n",
    "      const outputData = await model.run(feeds);\n",
    "      const end = new Date();\n",
    "      const inferenceTime = (end.getTime() - start.getTime());\n",
    "      const output = outputData[model.outputNames[0]];\n",
    "      return [output, inferenceTime];\n",
    "    } catch (e) {\n",
    "      console.error(e);\n",
    "      throw new Error();\n",
    "    }\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "const [res, time] =  await runModel(session, data);\n",
    "var output = res.data;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "function getMiniBoxes(contour) {\n",
    "    const boundingRect = cv.minAreaRect(contour)\n",
    "    const points = cv.RotatedRect.points(boundingRect).map(p => [p.x, p.y])\n",
    "    points.sort(p => p[0])\n",
    "\n",
    "    console.log({boundingRect})\n",
    "    \n",
    "    let [index_1, index_2, index_3, index_4] = [0, 1, 2, 3]\n",
    "    \n",
    "    if (points[1][1] > points[0][1]) {\n",
    "        index_1 = 0\n",
    "        index_4 = 1\n",
    "    } else {\n",
    "        index_1 = 1\n",
    "        index_4 = 0\n",
    "    }\n",
    "        \n",
    "    if (points[3][1] > points[2][1]) {\n",
    "        index_2 = 2\n",
    "        index_3 = 3\n",
    "    } else {\n",
    "        index_2 = 3\n",
    "        index_3 = 2\n",
    "    }\n",
    "\n",
    "    const box = [points[index_1], points[index_2], points[index_3], points[index_4]]\n",
    "    \n",
    "    return box\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred shape: \u001b[33m640\u001b[39m \u001b[33m640\u001b[39m\n",
      "segmentation shape: \u001b[33m640\u001b[39m \u001b[33m640\u001b[39m\n",
      "Found \u001b[33m1\u001b[39m contours\n",
      "{\n",
      "  boundingRect: {\n",
      "    center: { x: \u001b[33m316.0370788574219\u001b[39m, y: \u001b[33m315.68414306640625\u001b[39m },\n",
      "    size: { width: \u001b[33m34.479278564453125\u001b[39m, height: \u001b[33m464.4918212890625\u001b[39m },\n",
      "    angle: \u001b[33m-88.38645935058594\u001b[39m\n",
      "  }\n",
      "}\n",
      "Array\n"
     ]
    }
   ],
   "source": [
    "let outputVec = cv.matFromArray(640, 640, cv.CV_32FC1, res.data);\n",
    "console.log('pred shape:', outputVec.rows, outputVec.cols);\n",
    "\n",
    "const thres = 0.3;\n",
    "// Binarization\n",
    "const segmentation = new cv.Mat();\n",
    "cv.threshold(outputVec, segmentation, thres, 1.0, cv.THRESH_BINARY);\n",
    "console.log('segmentation shape:', segmentation.rows, segmentation.cols);\n",
    "\n",
    "const mask = segmentation.clone();\n",
    "const maskUint8 = new cv.Mat();\n",
    "mask.convertTo(maskUint8, cv.CV_8U, 255);\n",
    "\n",
    "const contours = new cv.MatVector();\n",
    "const hierarchy = new cv.Mat();\n",
    "cv.findContours(maskUint8, contours, hierarchy, cv.RETR_LIST, cv.CHAIN_APPROX_SIMPLE);\n",
    "console.log('Found', contours.size(), 'contours');\n",
    "\n",
    "for (let idx = 0; idx < contours.size(); idx++) {\n",
    "    const contour = contours.get(idx)\n",
    "    const points = getMiniBoxes(contour)\n",
    "    // const box = unclip(points, 2.0)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6f7c4d44365b28014734406e4d617c1e1f76ea196def854c7b951a230f6e24f1"
  },
  "kernelspec": {
   "display_name": "Deno",
   "language": "typescript",
   "name": "deno"
  },
  "language_info": {
   "codemirror_mode": "typescript",
   "file_extension": ".ts",
   "mimetype": "text/x.typescript",
   "name": "typescript",
   "nbconvert_exporter": "script",
   "pygments_lexer": "typescript",
   "version": "5.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
